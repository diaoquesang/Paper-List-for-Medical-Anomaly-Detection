<div id = "top"></div>

<div align="center">

[![](https://capsule-render.vercel.app/api?type=waving&height=200&color=timeGradient&text=üåü%20Paper%20List%20for%20Medical%20Anomaly%20Detection&fontSize=30&fontAlignY=40)
](#top)

</div>

<div align="center">
  

[![](https://img.shields.io/github/stars/diaoquesang/Paper-List-for-Medical-Anomaly-Detection)](https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection)
[![](https://img.shields.io/github/forks/diaoquesang/Paper-List-for-Medical-Anomaly-Detection)](https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection)
[![](https://img.shields.io/github/issues/diaoquesang/Paper-List-for-Medical-Anomaly-Detection)](https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/issues)
[![](https://img.shields.io/github/license/diaoquesang/Paper-List-for-Medical-Anomaly-Detection)](https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/LICENSE) 
[![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdiaoquesang%2FPaper-List-for-Medical-Anomaly-Detection&label=visitors&countColor=%2337d67a&style=flat&labelStyle=none)](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fdiaoquesang%2FPaper-List-for-Medical-Anomaly-Detection)

</div>

**ü¶â Contributors: [Yifei Sun (22' HDU-ITMO Undergraduate)](https://diaoquesang.github.io/), [Junhao Jia (23' HDU Undergraduate)](https://github.com/BeistMedAI), [Hao Zheng (22' HDU-ITMO Undergraduate)](https://github.com/267588), [Zhanghao Chen (21' HDU-ITMO Undergraduate/25' SEU Master)](https://benny0323.github.io/bio/), [Yuzhi He (23' XDU Undergraduate)](https://github.com/Black0226), [Jinhong Wang (21' ZJU PhD)](https://wang-jinhong.github.io/), [Jincheng Li (23' NTU Undergraduate)](https://github.com/li00000011).**

**üéì DeepWiki: [Generating GitHub Knowledge Base Documentation in One Click ](https://deepwiki.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection).**

**üì¶ Other resources: [1] [Bone Suppression in Chest X-Rays: A Deep Survey](https://github.com/diaoquesang/A-detailed-summarization-about-bone-suppression-in-Chest-X-rays), [2] [A Paper List for Prototypical Learning](https://github.com/BeistMedAI/Paper-List-for-Prototypical-Learning), [3] [A Paper List for Cell Detection](https://github.com/li00000011/Paper-List-for-Cell-Detection), [4] [Medical-AI-Guide](https://github.com/diaoquesang/Medical-AI-Guide/).**

### Welcome to join us by contacting: szhsxhsyf@hdu.edu.cn.

<div>
<img src="https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/logos/HDU.png" height="45px" href="https://www.hdu.edu.cn/">
<img src="https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/logos/ITMO.jpg" height="45px" href="https://en.itmo.ru/">
<img src="https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/logos/SEU.jpg" height="45px" href="https://www.seu.edu.cn/">
<img src="https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/logos/XDU.jpg" height="45px" href="https://www.xidian.edu.cn/">
<img src="https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/logos/ZJU.png" height="45px" href="https://www.zju.edu.cn/">
<img src="https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/logos/NTU.jpg" height="45px" href="https://www.ntu.edu.cn/">
<img src="https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/logos/SRIBD.png" height="45px" href="https://www.sribd.cn/">
<img src="https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/logos/CUHK-SZ.png" height="45px" href="https://www.cuhk.edu.cn/zh-hans">
</div>


## üìá Contents
- [**üìö Overview of Medical Imaging Anomaly Detection**](#s1)
- [**‚úèÔ∏è Tips**](#s2)
- [**üïê 1. Solving "Identical Shortcut"**](#s3)
- [**üïë 2. Discriminative Learning**](#s4)
- [**üïí 3. AE-Based Approaches**](#s5)
- [**üïì 4. GAN-Based Approaches**](#s6)
- [**üïî 5. Diffusion-Based Approaches**](#s7)
- [**üïï 6. Multi-Modal Fusion**](#s8)
- [**üïñ 7. Vision Language Models**](#s9)
- [**üïó 8. Knowledge Distillation**](#s10)
- [**üïò 9. Benchmarks**](#s11)
- [**ü•∞ Star History**](#s12)

## üìö Overview of Medical Imaging Anomaly Detection <div id = "s1"></div>

<div align="center">
  <img src="https://github.com/user-attachments/assets/1abc4d53-5138-4a0f-857a-1e9528b9bfcd" width="100%">
</div>

## ‚úèÔ∏è Tips <div id = "s2"></div>

- *: Papers for Non-Medical Anomaly Detection

- :octocat:: Code

## üïê 1. Solving "Identical Shortcut" <div id = "s3"></div>


- *[[NeurIPS 2022]](https://proceedings.neurips.cc/paper_files/paper/2022/file/1d774c112926348c3e25ea47d87c835b-Paper-Conference.pdf) **A Unified Model for Multi-class Anomaly Detection** [:octocat:](https://github.com/zhiyuanyou/uniad)

  *You, Zhiyuan and Cui, Lei and Shen, Yujun and Yang, Kai and Lu, Xin and Zheng, Yu and Le, Xinyi*

<div align="center">
  <img src="https://github.com/user-attachments/assets/ab761cad-56ed-4b6d-8d6d-c333762b992c" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>
Despite the rapid advance of unsupervised anomaly detection, existing methods require to train separate models for different objects. In this work, we present UniAD that accomplishes anomaly detection for multiple classes with a unified framework. Under such a challenging setting, popular reconstruction networks may fall into an" identical shortcut", where both normal and anomalous samples can be well recovered, and hence fail to spot outliers. To tackle this obstacle, we make three improvements. First, we revisit the formulations of fully-connected layer, convolutional layer, as well as attention layer, and confirm the important role of query embedding (ie, within attention layer) in preventing the network from learning the shortcut. We therefore come up with a layer-wise query decoder to help model the multi-class distribution. Second, we employ a neighbor masked attention module to further avoid the information leak from the input feature to the reconstructed output feature. Third, we propose a feature jittering strategy that urges the model to recover the correct message even with noisy inputs. We evaluate our algorithm on MVTec-AD and CIFAR-10 datasets, where we surpass the state-of-the-art alternatives by a sufficiently large margin. For example, when learning a unified model for 15 categories in MVTec-AD, we surpass the second competitor on the tasks of both anomaly detection (from 88.1% to 96.5%) and anomaly localization (from 89.5% to 96.8%). Code is available at https://github.com/zhiyuanyou/UniAD.
</details>

## üïë 2. Discriminative Learning <div id = "s4"></div>

- [[CVPR 2019]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Cascaded_Generative_and_Discriminative_Learning_for_Microcalcification_Detection_in_Breast_CVPR_2019_paper.pdf) **Cascaded Generative and Discriminative Learning for Microcalcification Detection in Breast Mammograms**

  *Zhang, Fandong and Luo, Ling and Sun, Xinwei and Zhou, Zhen and Li, Xiuli and Yu, Yizhou and Wang, Yizhou*

<div align="center">
  <img src="https://github.com/user-attachments/assets/41569c42-7921-4602-9a35-cad58b06147e" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>
Accurate microcalcification (mC) detection is of great importance due to its high proportion in early breast cancers. Most of the previous mC detection methods belong to discriminative models, where classifiers are exploited to distinguish mCs from other backgrounds. However, it is still challenging for these methods to tell the mCs from amounts of normal tissues because they are too tiny (at most 14 pixels). Generative methods can precisely model the normal tissues and regard the abnormal ones as outliers, while they fail to further distinguish the mCs from other anomalies, ie vessel calcifications. In this paper, we propose a hybrid approach by taking advantages of both generative and discriminative models. Firstly, a generative model named Anomaly Separation Network (ASN) is used to generate candidate mCs. ASN contains two major components. A deep convolutional encoder-decoder network is built to learn the image reconstruction mapping and a t-test loss function is designed to separate the distributions of the reconstruction residuals of mCs from normal tissues. Secondly, a discriminative model is cascaded to tell the mCs from the false positives. Finally, to verify the effectiveness of our method, we conduct experiments on both public and in-house datasets, which demonstrates that our approach outperforms previous state-of-the-art methods.
</details>

## üïí 3. AE-Based Approaches <div id = "s5"></div>

- [[MICCAI 2024]](https://arxiv.org/pdf/2403.09303) **Rethinking Autoencoders for Medical Anomaly Detection from a Theoretical Perspective** [:octocat:](https://github.com/caiyu6666/ae4ad)

  *Cai, Yu and Chen, Hao and Cheng, Kwang-Ting*

<div align="center">
  <img src="https://github.com/user-attachments/assets/25d5c2b4-d2d9-4d1a-a90e-c8651dc01f9d" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>
Medical anomaly detection aims to identify abnormal findings using only normal training data, playing a crucial role in health screening and recognizing rare diseases. Reconstruction-based methods, particularly those utilizing autoencoders (AEs), are dominant in this field. They work under the assumption that AEs trained on only normal data cannot reconstruct unseen abnormal regions well, thereby enabling the anomaly detection based on reconstruction errors. However, this assumption does not always hold due to the mismatch between the reconstruction training objective and the anomaly detection task objective, rendering these methods theoretically unsound. This study focuses on providing a theoretical foundation for AE-based reconstruction methods in anomaly detection. By leveraging information theory, we elucidate the principles of these methods and reveal that the key to improving AE in anomaly detection lies in minimizing the information entropy of latent vectors. Experiments on four datasets with two image modalities validate the effectiveness of our theory. To the best of our knowledge, this is the first effort to theoretically clarify the principles and design philosophy of AE for anomaly detection. The code is available at https://github.com/caiyu6666/AE4AD.
</details>
  
- [[ICLR 2023]](https://openreview.net/pdf?id=9OmCr1q54Z) **AE-FLOW: Autoencoders with Normalizing Flows for Medical Images Anomaly Detection**

  *Zhao, Yuzhong and Ding, Qiaoqiao and Zhang, Xiaoqun*

<div align="center">
  <img src="https://github.com/user-attachments/assets/cb07b128-80eb-4c1b-b606-664e2a866675" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>
Anomaly detection from medical images is an important task for clinical screening and diagnosis. In general, a large dataset of normal images are available while only few abnormal images can be collected in clinical practice. By mimicking the diagnosis process of radiologists, we attempt to tackle this problem by learning a tractable distribution of normal images and identify anomalies by differentiating the original image and the reconstructed normal image. More specifically, we propose a normalizing flow-based autoencoder for an efficient and tractable representation of normal medical images. The anomaly score consists of the likelihood originated from the normalizing flow and the reconstruction error of the autoencoder, which allows to identify the abnormality and provide an interpretability at both image and pixel levels. Experimental evaluation on two medical images datasets showed that the proposed model outperformed the other approaches by a large margin, which validated the effectiveness and robustness of the proposed method.
</details>
  
- [[MedIA 2023]](https://arxiv.org/pdf/2301.08330) **The Role of Noise in Denoising Models for Anomaly Detection in Medical Images** [:octocat:](https://github.com/antanaskascenas/denoisingae)

  *Kascenas, Antanas and Sanchez, Pedro and Schrempf, Patrick and Wang, Chaoyang and Clackett, William and Mikhael, Shadia S and Voisey, Jeremy P and Goatman, Keith and Weir, Alexander and Pugeault, Nicolas and others*

<div align="center">
  <img src="https://github.com/user-attachments/assets/eb0d29f9-1697-423a-83c3-a111a3097182" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>
Pathological brain lesions exhibit diverse appearance in brain images, in terms of intensity, texture, shape, size, and location. Comprehensive sets of data and annotations are difficult to acquire. Therefore, unsupervised anomaly detection approaches have been proposed using only normal data for training, with the aim of detecting outlier anomalous voxels at test time. Denoising methods, for instance classical denoising autoencoders (DAEs) and more recently emerging diffusion models, are a promising approach, however naive application of pixelwise noise leads to poor anomaly detection performance. We show that optimization of the spatial resolution and magnitude of the noise improves the performance of different model training regimes, with similar noise parameter adjustments giving good performance for both DAEs and diffusion models. Visual inspection of the reconstructions suggests that the training noise influences the trade-off between the extent of the detail that is reconstructed and the extent of erasure of anomalies, both of which contribute to better anomaly detection performance. We validate our findings on two real-world datasets (tumor detection in brain MRI and hemorrhage/ischemia/tumor detection in brain CT), showing good detection on diverse anomaly appearances. Overall, we find that a DAE trained with coarse noise is a fast and simple method that gives state-of-the-art accuracy. Diffusion models applied to anomaly detection are as yet in their infancy and provide a promising avenue for further research. Code for our DAE model and coarse noise is provided at: https://github.com/AntanasKascenas/DenoisingAE.
</details>
  
## üïì 4. GAN-Based Approaches <div id = "s6"></div>

- [[Neurocomputing 2025]](https://www.sciencedirect.com/science/article/pii/S0925231224015339) **Industrial and Medical Anomaly Detection Through Cycle-Consistent Adversarial Networks** [:octocat:](https://github.com/valdelch/cyclegans-anomalydetection)

  *Bougaham, Arnaud and Delchevalerie, Valentin and El Adoui, Mohammed and Fr√©nay, Beno√Æt*

<div align="center">
  <img src="https://github.com/user-attachments/assets/f05671aa-c0d5-45a8-a4a7-9afec22e84a5" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
- [[PR 2024]](https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/handle/11250/3178214/2229397_Article_.pdf?sequence=1) **Anomaly Detection via Gating Highway Connection for Retinal Fundus Images** [:octocat:](https://github.com/WentianZhang-ML/GatingAno)

  *Zhang, Wentian and Liu, Haozhe and Xie, Jinheng and Huang, Yawen and Zhang, Yu and Li, Yuexiang and Ramachandra, Raghavendra and Zheng, Yefeng*

<div align="center">
  <img src="https://github.com/user-attachments/assets/b017215e-0998-4e63-97f9-7a5271756c68" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
- [[CVPR 2023]](http://openaccess.thecvf.com/content/CVPR2023/papers/Xiang_SQUID_Deep_Feature_In-Painting_for_Unsupervised_Anomaly_Detection_CVPR_2023_paper.pdf) **SQUID: Deep Feature In-Painting for Unsupervised Anomaly Detection** [:octocat:](https://github.com/tiangexiang/squid)


  *Xiang, Tiange and Zhang, Yixiao and Lu, Yongyi and Yuille, Alan L and Zhang, Chaoyi and Cai, Weidong and Zhou, Zongwei*

<div align="center">
  <img src="https://github.com/user-attachments/assets/8ed73cd7-6b22-4e7e-be06-4d5c97e7ab80" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
## üïî 5. Diffusion-Based Approaches <div id = "s7"></div>

- [[CVPR 2025]](https://arxiv.org/abs/2406.01078) **Anomaly Anything: Promptable Unseen Visual Anomaly Generation** [:octocat:](https://github.com/EPFL-IMOS/AnomalyAny)

  *Sun, Han and Cao, Yunkang and Dong, Hao and Fink, Olga*

<div align="center">
  <img src="https://github.com/user-attachments/assets/dfc56b79-f820-49dd-9d38-683836852289" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>

- [[WACV 2025]](https://www.researchgate.net/profile/Sudipta-Roy-9/publication/389540571_Self-Supervised_Anomaly_Segmentation_via_Diffusion_Models_with_Dynamic_Transformer_UNet/links/67c6e067461fb56424f04c9f/Self-Supervised-Anomaly-Segmentation-via-Diffusion-Models-with-Dynamic-Transformer-UNet.pdf) **Self-Supervised Anomaly Segmentation via Diffusion Models with Dynamic Transformer UNet** [:octocat:](https://github.com/MAXNORM8650/Annotsim)

  *Kumar, Komal and Chakraborty, Snehashis and Mahapatra, Dwarikanath and Bozorgtabar, Behzad and Roy, Sudipta*

<div align="center">
  <img src="https://github.com/user-attachments/assets/9e601d52-d982-437e-9b69-b1ade659d54b" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
- [[TMI 2024]](https://arxiv.org/pdf/2308.02062) **Diffusion Models for Counterfactual Generation and Anomaly Detection in Brain lmages** [:octocat:](https://github.com/alessandro-f/dif-fuse)

  *Fontanella, Alessandro and Mair, Grant and Wardlaw, Joanna and Trucco, Emanuele and Storkey, Amos*

<div align="center">
  <img src="https://github.com/user-attachments/assets/48f34db0-8ffb-494d-830f-8ce4b79bd00e" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
- [[MICCAI 2024]](https://arxiv.org/pdf/2403.08464) **Diffusion Models with Implicit Guidance for Medical Anomaly Detection** [:octocat:](https://github.com/ci-ber/thor_ddpm)

  *Bercea, Cosmin I and Wiestler, Benedikt and Rueckert, Daniel and Schnabel, Julia A*

<div align="center">
  <img src="https://github.com/user-attachments/assets/b5860d4f-eaaf-44bf-a0ea-1279f7d35446" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
- [[MIDL 2024]](https://proceedings.mlr.press/v227/behrendt24a/behrendt24a.pdf) **Patched Diffusion Models for Unsupervised Anomaly Detection in Brain MRI** [:octocat:](https://github.com/finnbehrendt/patched-diffusion-models-uad)

  *Behrendt, Finn and Bhattacharya, Debayan and Kr√ºger, Julia and Opfer, Roland and Schlaefer, Alexander*

<div align="center">
  <img src="https://github.com/user-attachments/assets/e5a30138-71c4-4a12-a78b-5ae3c48a3c59" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>

- [[UNSURE 2024]](https://link.springer.com/chapter/10.1007/978-3-031-73158-7_11) **Image-Conditioned Diffusion Models for Medical Anomaly Detection**

  *Baugh, Matthew and Reynaud, Hadrien and Marimont, Sergio Naval and Cechnicka, Sarah and M{\"u}ller, Johanna P and Tarroni, Giacomo and Kainz, Bernhard*

<div align="center">
  <img src="https://github.com/user-attachments/assets/e4bd523f-f71e-45ed-825c-9024144a6fdc" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>

- [[CVPR 2022]](https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Wyatt_AnoDDPM_Anomaly_Detection_With_Denoising_Diffusion_Probabilistic_Models_Using_Simplex_CVPRW_2022_paper.pdf) **AnoDDPM: Anomaly Detection with Denoising Diffusion Probabilistic Models using Simplex Noise** [:octocat:](https://github.com/julian-wyatt/anoddpm)

  *Wyatt, Julian and Leach, Adam and Schmon, Sebastian M and Willcocks, Chris G*

<div align="center">
  <img src="https://github.com/user-attachments/assets/5e738dcc-ba84-4446-b996-9cc493f37bb9" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
- [[MICCAI 2022]](https://arxiv.org/pdf/2203.04306) **Diffusion Models for Medical Anomaly Detection** [:octocat:](https://github.com/JuliaWolleb/diffusion-anomaly)

  *Wolleb, Julia and Bieder, Florentin and Sandk√ºhler, Robin and Cattin, Philippe C*

<div align="center">
  <img src="https://github.com/user-attachments/assets/d26c0351-cf7d-4e8c-84d4-66f081f370ad" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
## üïï 6. Multi-Modal Fusion <div id = "s8"></div>

- [[IF 2025]](https://www.sciencedirect.com/science/article/pii/S1566253524004093) **Adapting the Segment Anything Model for Multi-Modal Retinal Anomaly Detection and Localization** [:octocat:](https://github.com/Jingtao-Li-CVer/MMRAD)

  *Li, Jingtao and Chen, Ting and Wang, Xinyu and Zhong, Yanfei and Xiao, Xuan*

<div align="center">
  <img src="https://github.com/user-attachments/assets/73accda9-cf6e-4e65-a358-15977e521198" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
- *[[AAAI 2025]](https://arxiv.org/pdf/2412.17297) **Revisiting Multimodal Fusion for 3D Anomaly Detection from an Architectural Perspective**

  *Long, Kaifang and Xie, Guoyang and Ma, Lianbo and Liu, Jiaqi and Lu, Zhichao*

<div align="center">
  <img src="https://github.com/user-attachments/assets/2dd4d4f9-dbb5-4dee-b271-3deaa56ea093" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
  
## üïñ 7. Vision Language Models <div id = "s9"></div>

- [[CVPR 2025]](https://arxiv.org/pdf/2503.06661) **AA-CLIP: Enhancing Zero-Shot Anomaly Detection via Anomaly-Aware CLIP** [:octocat:](https://github.com/mwxinnn/aa-clip)

  *Ma, Wenxin and Zhang, Xu and Yao, Qingsong and Tang, Fenghe and Wu, Chenxu and Li, Yingtai and Yan, Rui and Jiang, Zihang and Zhou, S Kevin*

<div align="center">
  <img src="https://github.com/user-attachments/assets/86849a66-3de5-4fec-9120-57b5b98aec11" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>

- [[NeurIPS 2024]](https://proceedings.neurips.cc/paper_files/paper/2024/hash/8f4477b086a9c97e30d1a0621ea6b2f5-Abstract-Conference.html) **One-to-Normal: Anomaly Personalization for Few-shot Anomaly Detection**

  *Li, Yiyue and Zhang, Shaoting and Li, Kang and Lao, Qicheng*

<div align="center">
  <img src="https://github.com/user-attachments/assets/ed1c9537-0238-4bb1-b7d9-df0b7148e3d7" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>

- [[CVPR 2024]](http://openaccess.thecvf.com/content/CVPR2024/papers/Zhu_Toward_Generalist_Anomaly_Detection_via_In-context_Residual_Learning_with_Few-shot_CVPR_2024_paper.pdf) **Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts** [:octocat:](https://github.com/mala-lab/inctrl)

  *Zhu, Jiawen and Pang, Guansong*

<div align="center">
  <img src="https://github.com/user-attachments/assets/98f8cda7-31e2-4205-a374-f57074a36e00" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
- [[CVPR 2024]](https://arxiv.org/abs/2403.12570) **Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images** [:octocat:](https://github.com/mediabrain-sjtu/mvfa-ad)

  *Huang, Chaoqin and Jiang, Aofan and Feng, Jinghao and Zhang, Ya and Wang, Xinchao and Wang, Yanfeng*
  
<div align="center">
  <img src="https://github.com/user-attachments/assets/f5ed3f7b-d2cd-4291-8280-5a3c7934040f" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>

- [[ICLR 2024]](https://openreview.net/forum?id=buC4E91xZE) **AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection** [:octocat:](https://github.com/zqhang/anomalyclip)

  *Zhou, Qihang and Pang, Guansong and Tian, Yu and He, Shibo and Chen, Jiming*
  
<div align="center">
  <img src="https://github.com/user-attachments/assets/2e56974f-5ac6-489e-b2b1-75cfa910e4cf" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
- [[MICCAI 2024]](https://arxiv.org/pdf/2405.11315) **Mediclip: Adapting CLIP for Few-shot Medical Image Anomaly Detection** [:octocat:](https://github.com/cnulab/mediclip)

  *Zhang, Ximiao and Xu, Min and Qiu, Dehui and Yan, Ruixin and Lang, Ning and Zhou, Xiuzhuang*

<div align="center">
  <img src="https://github.com/user-attachments/assets/9c1c39d0-b284-4ae2-b7f9-a5a62315b16c" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
## üïó 8. Knowledge Distillation <div id = "s10"></div>

- *[[AAAI 2025]](https://arxiv.org/pdf/2412.07579) **Unlocking the Potential of Reverse Distillation for Anomaly Detection** [:octocat:](https://github.com/hito2448/urd)


  *Liu, Xinyue and Wang, Jianyuan and Leng, Biao and Zhang, Shuo*

<div align="center">
  <img src="https://github.com/user-attachments/assets/38ced3db-a3d3-4dbb-8691-308739ac5a03" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>
  
## üïò 9. Benchmarks <div id = "s11"></div>

- [[Nature Communications 2025]](https://www.nature.com/articles/s41467-025-56321-y) **Evaluating Normative Representation Learning in Generative AI for Robust Anomaly Detection in Brain Imaging**

  *Bercea, Cosmin I and Wiestler, Benedikt and Rueckert, Daniel and Schnabel, Julia A*

<div align="center">
  <img src="https://github.com/user-attachments/assets/03824efc-a4f8-4045-8114-8ed610015778" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>

- [[MedIA 2025]](https://arxiv.org/pdf/2404.04518) **MedIAnomaly: A Comparative Study of Anomaly Detection in Medical Images** [:octocat:](https://github.com/caiyu6666/medianomaly)

  *Cai, Yu and Zhang, Weiwen and Chen, Hao and Cheng, Kwang-Ting*

<div align="center">
  <img src="https://github.com/user-attachments/assets/59e43d96-2bfc-4bce-ab5a-282cf2c06c3c" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>

- [[CVPR 2024]](https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Bao_BMAD_Benchmarks_for_Medical_Anomaly_Detection_CVPRW_2024_paper.html) **BMAD: Benchmarks for Medical Anomaly Detection** [:octocat:](https://github.com/dorisbao/bmad)

  *Bao, Jinan and Sun, Hanshi and Deng, Hanqiu and He, Yinsheng and Zhang, Zhaoxiang and Li, Xingyu*

<div align="center">
  <img src="https://github.com/user-attachments/assets/8c64c38c-2485-4c9c-ab85-9aeb3386fb9d" width="50%">
</div>

<details close>
<summary><b>üìã Abstract (Click to Expand)</b></summary>

</details>

## ü•∞ Star History <div id = "s12"></div>
[![Star History Chart](https://api.star-history.com/svg?repos=diaoquesang/Paper-List-for-Medical-Anomaly-Detection&type=Date)](https://star-history.com/#diaoquesang/Paper-List-for-Medical-Anomaly-Detection&Date)

[![](https://capsule-render.vercel.app/api?type=waving&height=200&color=timeGradient&text=Back%20to%20Top&section=footer&fontSize=30&fontAlignY=65)
](#top)
